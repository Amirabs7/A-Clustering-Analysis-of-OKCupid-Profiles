# -*- coding: utf-8 -*-
"""Uncovering Dating Archetypes: Clustering OKCupid Profiles Using UMAP and KMeans

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w4ndUTjK7G46MXmfkJL_IfV_Qqlvomqj

OkCupid is a mobile dating app. It sets itself apart from other dating apps by making use of a pre computed compatibility score, calculated by optional questions the users may choose to answer.

In this dataset, there are 60k records containing structured information such as age, sex, orientation as well as text data from open ended descriptions.

Data set retrived from: https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles/data
"""

from google.colab import files
uploaded = files.upload()

"""# Data Cleaning and Preprocessing


"""

import pandas as pd

# Load the CSV into a DataFrame
df = pd.read_csv('okcupid_profiles.csv')

# Show the first few rows
df.head()

# See how many missing values each column has
df.isnull().sum().sort_values(ascending=False)

# Drop columns with > 20,000 missing values (adjust threshold as needed)
to_drop = ['offspring', 'diet', 'religion', 'pets', 'essay8']
df = df.drop(columns=to_drop)

fill_unknown = ['drugs', 'sign', 'body_type', 'drinks', 'job', 'education', 'ethnicity', 'smokes', 'speaks']
df[fill_unknown] = df[fill_unknown].fillna('unknown')

cols_to_drop = ['essay0','essay1','essay2','essay3','essay4','essay5','essay6','essay7','essay8','essay9']
existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]
df = df.drop(columns=existing_cols_to_drop)

fill_unknown = ['drugs', 'sign', 'body_type', 'drinks', 'job', 'education', 'ethnicity', 'smokes', 'speaks']
df[fill_unknown] = df[fill_unknown].fillna('unknown')

# Only keep rows with non-null height (3 missing)
df = df.dropna(subset=['height'])

df.isnull().sum().sort_values(ascending=False)

df.duplicated().sum()

"""# Exploratory Data Analysis (EDA) — distributions, correlations, visualizations


"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set seaborn style for nicer plots
sns.set(style="whitegrid")

""" Basic distributions of key numeric variables

"""

plt.figure(figsize=(8,5))
sns.histplot(df['age'], bins=30, kde=True, color='skyblue')
plt.title('Age Distribution')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

# Keep income between $1 and $200,000 (reasonable range)
df_income_filtered = df[(df['income'] > 0) & (df['income'] <= 200000)]

plt.figure(figsize=(8, 5))
sns.histplot(df_income_filtered['income'], bins=30, kde=True, color='teal')
plt.title('Income Distribution (Filtered: $1 to $200K)')
plt.xlabel('Annual Income (USD)')
plt.ylabel('Count')
plt.show()

"""Bar charts for categorical variables

"""

plt.figure(figsize=(10,6))
sns.countplot(y='body_type', data=df, order=df['body_type'].value_counts().index, palette='pastel')
plt.title('Body Type Counts')
plt.xlabel('Count')
plt.ylabel('Body Type')
plt.show()

plt.figure(figsize=(10,6))
sns.countplot(y='education', data=df, order=df['education'].value_counts().index, palette='muted')
plt.title('Education Level Counts')
plt.xlabel('Count')
plt.ylabel('Education Level')
plt.show()

"""Cross-tabulation / relationships

"""

plt.figure(figsize=(8,5))
sns.boxplot(x='sex', y='age', data=df, palette='Set2')
plt.title('Age Distribution by Sex')
plt.xlabel('Sex')
plt.ylabel('Age')
plt.show()

# Remove zero or missing income (assuming 0 means missing or no data)
df_income_clean = df[df['income'] > 0]
median_income_by_edu = df_income_clean.groupby('education')['income'].median().sort_values(ascending=False)

plt.figure(figsize=(10,5))
sns.barplot(x=median_income_by_edu.values, y=median_income_by_edu.index, palette='viridis')
plt.title('Median Income by Education Level')
plt.xlabel('Median Income')
plt.ylabel('Education Level')
plt.show()

"""Correlations

"""

plt.figure(figsize=(10,6))
sns.pointplot(x='orientation', y='drinks', data=df, join=False, capsize=0.2, palette='muted')
plt.title('Drinking Frequency by Sexual Orientation')
plt.xticks(rotation=45)
plt.show()

drink_order = ['not at all', 'rarely', 'socially', 'often', 'very often', 'desperately']
df['drinks_num'] = df['drinks'].apply(lambda x: drink_order.index(x) if x in drink_order else -1)

plt.figure(figsize=(8,5))
sns.boxplot(x='drinks_num', y='income', data=df[df['income'] > 0])
plt.title('Income by Drinking Frequency (Encoded)')
plt.xlabel('Drinking Frequency (0=Not at all, 5=Desperately)')
plt.ylabel('Income')
plt.show()

"""# Dimensionality Reduction with UMAP


"""

import umap.umap_ as umap
from sklearn.preprocessing import LabelEncoder

# Encode categorical variables
le_sex = LabelEncoder()
df_viz['sex_enc'] = le_sex.fit_transform(df['sex'])

# Select numeric features + encoded categoricals
features = ['age', 'income', 'height', 'sex_enc']

# Fill NaNs with median or -1
X = df_viz[features].fillna(-1)

# Run UMAP
reducer = umap.UMAP(random_state=42)
embedding = reducer.fit_transform(X)

plt.figure(figsize=(10,8))
sns.scatterplot(x=embedding[:,0], y=embedding[:,1], hue=df['sex'], palette='Set1', alpha=0.7)
plt.title('UMAP projection of OKCupid Profiles')
plt.show()

"""This code uses UMAP, a dimensionality reduction technique, to project user profiles into a 2D space based on selected numerical and encoded categorical features (age, income, height, and sex).

LabelEncoder converts the sex column from text (e.g. 'm', 'f') to numbers so it can be included in the analysis.

Missing values are filled with -1 to avoid errors during processing.

UMAP then transforms the high-dimensional feature set into a 2D representation that preserves relationships between similar profiles.

Finally, the result is visualized with a scatterplot, where each point is a profile and the color represents the user’s sex.

The plot helps identify natural clusters or patterns among profiles based on basic demographic traits.

Who Goes Together? Cluster Analysis of OKCupid Users Using UMAP and KMeans
"""

print(df.columns)

"""# Clustering with KMeans and cluster interpretation


"""

from sklearn.preprocessing import LabelEncoder
import umap.umap_ as umap
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import seaborn as sns
import matplotlib.pyplot as plt

# Copy the DataFrame
df_viz = df.copy()

# Choose categorical features to encode
categorical_cols = ['sex', 'drinks', 'education', 'orientation', 'smokes', 'job']

# Encode them
for col in categorical_cols:
    df_viz[col + '_enc'] = LabelEncoder().fit_transform(df_viz[col].astype(str))

# Select features for clustering and visualization
features = ['age', 'income', 'height'] + [col + '_enc' for col in categorical_cols]
X = df_viz[features].fillna(-1)

# Run UMAP
reducer = umap.UMAP(random_state=42)
embedding = reducer.fit_transform(X)

# Run KMeans clustering
kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(X)
df_viz['cluster'] = labels

# Silhouette score
score = silhouette_score(X, labels)
print(f"Silhouette Score: {score:.3f}")

# Plot UMAP
plt.figure(figsize=(10, 8))
sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=df_viz['cluster'], palette='Set2', alpha=0.8)
plt.title('UMAP Projection of OKCupid Profiles by Cluster')
plt.show()

"""Interpretation of Your UMAP Clustering Plot
The UMAP projection maps the high-dimensional profile data into a 2D space, where each point represents a user.

The x-axis ranges roughly from -10 to 20, and the y-axis from -5 to 20, which is normal since UMAP axes are abstract and show relative distances, not literal values.

You identified 5 clusters (0 to 4), each shown with a different color.

The largest cluster (cluster 1) dominates the area around:

X between 0 and 5

Y between 10 and 20

and also a spread between X = 5 to 20 (right side of the plot).

Other clusters (0, 2, 3, 4) mostly group around:

X values between -5 and 0

Y values between 0 and 5

This spatial separation means:

Cluster 1 profiles share similar traits, distinct from other clusters, placing them in the upper-right region of the plot.

Clusters 0, 2, 3, 4 represent smaller, more tightly grouped profile types closer to the center-left of the plot.

The spread and density suggest Cluster 1 captures the majority with possibly more common demographic or lifestyle patterns, while the other clusters may represent niche or outlier profile groups.


"""

print(df_viz.groupby('cluster')[features].mean())

"""# Insights and Conclusions

Since Cluster 1 is the biggest group and has the following characteristics:

Younger average age (~32 years)

Very low average income (~1,147)

High education level (~14.7, suggesting college or higher)

Moderate height (~68.1 inches)

Mixed sex distribution (sex_enc ~0.57)

Moderate drinking habits (~3.62)

Higher job encoding (likely representing various job types)

What This Suggests About the Overall Dataset:
Youthful and Educated Majority:
The largest segment of your dataset consists primarily of younger, well-educated individuals—likely reflecting a strong presence of students, recent graduates, or early-career professionals.

Low Income Despite Education:
Despite high education levels, this group has very low income, which could mean many are still in school, internships, entry-level roles, or part-time jobs.

Diverse Gender Representation:
The mixed sex encoding indicates no strong gender skew, so this group fairly represents both males and females.

Lifestyle Habits:
Moderate drinking and job diversity suggest a typical young adult lifestyle with varied social and professional backgrounds.

Data Skew:
Since this group is much bigger than others, your dataset likely overrepresents this demographic. That means your insights will be most reflective of younger, educated, lower-income users rather than older or higher-income populations.
"""